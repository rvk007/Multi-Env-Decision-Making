# env
env:
  config_dir: env_configs
  save_video: true
  fps: 5
  names:
    - highway-v0
    - merge-v0
    - roundabout-v0

mode: train

# train
num_train_steps: 60000
num_gradient_steps: 1
num_exploration_steps: 1500
start_training_steps: 600
min_eps: 0.05
replay_buffer_capacity: 45000
# Prioritized Replay Buffer
prioritized_replay: false
prioritized_replay_alpha: 0.6
seed: 42
# eval
eval_frequency: 1500
num_eval_steps: 3000
# misc
log_frequency_step: 300
log_save_tb: true
device: cuda
# global params
lr: 0.0005
beta_1: 0.9
beta_2: 0.999
weight_decay: 0.0
adam_eps: 0.00015
max_grad_norm: 10.0
batch_size: 32
save_checkpoint: true

# agent configuration
agent:
  name: drql
  class: drql.DRQLAgent
  params:
    obs_shape: ??? # to be specified later
    action_shape: ??? # to be specified later
    num_env_paths: ??? # to be specified later
    device: ${device}
    encoder_cfg: ${encoder}
    critic_cfg: ${critic}
    discount: 0.8
    lr: ${lr}
    beta_1: ${beta_1}
    beta_2: ${beta_2}
    weight_decay: ${weight_decay}
    adam_eps: ${adam_eps}
    max_grad_norm: ${max_grad_norm}
    critic_tau: 1.0
    critic_target_update_frequency: 50
    batch_size: ${batch_size}
    multistep_return: 10
    eval_eps: 0.05
    # Double Q learning
    double_q: true
    prioritized_replay_beta0: 0.4
    prioritized_replay_beta_steps: ${num_train_steps}

critic:
  class: drql.Critic
  params:
    encoder_cfg: ${agent.params.encoder_cfg}
    action_shape: ${agent.params.action_shape}
    num_env_paths: ${agent.params.num_env_paths}
    hidden_dim: 256
    hidden_depth: 1
    # Dueling DQN
    dueling: false

encoder:
  class: drql.Encoder
  params:
    input_shape: ${agent.params.obs_shape}
    hidden_dim: 256
    hidden_depth: 1

experiment: hmr

# hydra configuration
hydra:
  name: ddqn
  run:
    dir: ./exp_local/${hydra.name}_${experiment}
  sweep:
    dir: ./exp/${hydra.name}/${now:%H%M%S}_${agent.name}_${experiment}
    subdir: ${hydra.job.num}
